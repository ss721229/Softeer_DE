### 리뷰
- 개인 미션
    - 오늘 개인 미션 M3 ~ M6까지 모두 마무리하였다. M1 ~ M2b까지 Docker로 Hadoop을 구축하는데 정말 시간이 많이 들어서 걱정되었다. 그리고 오전 강의에서 미션이 정말 중요하다고 꼭 이번 주 내에 마무리하라는 이야기를 듣고, 초집중하여 과제를 마물리할 수 있었다. 또한 M3 ~ M6은 MapReduce Code를 작성할 뿐이라 이전 미션보다 쉽게 수행할 수 있었다.
    - M6을 수행하면서 Review 데이터가 카테고리 별로 있었기 때문에 어떤 데이터를 사용해야 할지 고민하였다. 그냥 모든 데이터를 사용하자는 결론이 났고, 데이터 다운로드, 압축 해제, HDFS 업로드 등을 python과 bash 코드로 작성하였다. 확인해보니 데이터가 300MB부터 20GB까지 정말 다양했기 때문에 용량 이슈가 생길까 살짝 걱정되었다. 그리고 실제로 이슈가 발생하였다.
    - Reducer의 메모리 초과로 인한 에러가 발생해 제대로 수행되지 않았다. 이를 방지하기 위해 프로세스의 힙 메모리를 제한하고, reducer와 mapper에 할당되는 메모리를 증가시켰다.
### 회고
- Keep
    - 여러 데이터 다운로드 및 압축 풀기를 일일이 진행하기 시간이 오래 걸릴 것 같았는데, python과 sh 파일을 만들어 팀원과 공유하였다. (그래도 용량이 커서 오래 걸렸지만..) 자동화하고 다른 사람과 공유한 것에 의의가 있다고 생각한다. 귀찮음을 개선하는 것을 멈추지 말자.
- Problem
    - \-
- Try
    - \-