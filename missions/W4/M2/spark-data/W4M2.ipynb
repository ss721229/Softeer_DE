{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cd1a3fd-759a-4f4a-99f8-a5a5997bb26b",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "1bc51772-c5b9-4ea8-9910-02c8011ae104",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from random import random\n",
    "from operator import add\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, count, hour, avg, unix_timestamp, sum as spark_sum\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "106829a0-dd7a-472b-8105-08fe308fa360",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openmeteo-requests in /usr/local/lib/python3.10/site-packages (1.6.0)\n",
      "Requirement already satisfied: openmeteo-sdk>=1.20.1 in /usr/local/lib/python3.10/site-packages (from openmeteo-requests) (1.20.1)\n",
      "Requirement already satisfied: niquests>=3.14.1 in /usr/local/lib/python3.10/site-packages (from openmeteo-requests) (3.14.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from niquests>=3.14.1->openmeteo-requests) (3.4.2)\n",
      "Requirement already satisfied: urllib3-future<3,>=2.12.900 in /usr/local/lib/python3.10/site-packages (from niquests>=3.14.1->openmeteo-requests) (2.13.900)\n",
      "Requirement already satisfied: wassima<2,>=1.0.1 in /usr/local/lib/python3.10/site-packages (from niquests>=3.14.1->openmeteo-requests) (1.2.2)\n",
      "Requirement already satisfied: flatbuffers==25.2.10 in /usr/local/lib/python3.10/site-packages (from openmeteo-sdk>=1.20.1->openmeteo-requests) (25.2.10)\n",
      "Requirement already satisfied: qh3<2.0.0,>=1.5.3 in /usr/local/lib/python3.10/site-packages (from urllib3-future<3,>=2.12.900->niquests>=3.14.1->openmeteo-requests) (1.5.3)\n",
      "Requirement already satisfied: h11<1.0.0,>=0.11.0 in /usr/local/lib/python3.10/site-packages (from urllib3-future<3,>=2.12.900->niquests>=3.14.1->openmeteo-requests) (0.16.0)\n",
      "Requirement already satisfied: jh2<6.0.0,>=5.0.3 in /usr/local/lib/python3.10/site-packages (from urllib3-future<3,>=2.12.900->niquests>=3.14.1->openmeteo-requests) (5.0.9)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/29 09:57:28 WARN TaskSetManager: Lost task 0.3 in stage 8.0 (TID 133) (172.18.0.3 executor 0): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 2044, in main\n",
      "    process()\n",
      "  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 2034, in process\n",
      "    out_iter = func(split_index, iterator)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/pyspark/core/rdd.py\", line 5306, in pipeline_func\n",
      "    return func(split, prev_func(split, iterator))\n",
      "  File \"/usr/local/lib/python3.10/site-packages/pyspark/core/rdd.py\", line 5306, in pipeline_func\n",
      "    return func(split, prev_func(split, iterator))\n",
      "  File \"/usr/local/lib/python3.10/site-packages/pyspark/core/rdd.py\", line 705, in func\n",
      "    return f(iterator)\n",
      "  File \"/tmp/ipykernel_177/3552365638.py\", line 2, in fetch_weather_partition\n",
      "ModuleNotFoundError: No module named 'openmeteo_requests'\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:581)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:940)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:925)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:532)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.mutable.Growable.addAll(Growable.scala:61)\n",
      "\tat scala.collection.mutable.Growable.addAll$(Growable.scala:57)\n",
      "\tat scala.collection.mutable.ArrayBuilder.addAll(ArrayBuilder.scala:75)\n",
      "\tat scala.collection.IterableOnceOps.toArray(IterableOnce.scala:1505)\n",
      "\tat scala.collection.IterableOnceOps.toArray$(IterableOnce.scala:1498)\n",
      "\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n",
      "\tat org.apache.spark.api.python.PythonRDD$.$anonfun$runJob$1(PythonRDD.scala:189)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2524)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "\n",
      "25/07/29 09:57:28 ERROR TaskSetManager: Task 0 in stage 8.0 failed 4 times; aborting job\n",
      "[Stage 6:====>                                                     (7 + 1) / 99]"
     ]
    }
   ],
   "source": [
    "pip install openmeteo-requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "476a0aa9-8844-485c-b608-cb106cb4afc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests-cache in /usr/local/lib/python3.10/site-packages (1.2.1)\n",
      "Requirement already satisfied: retry-requests in /usr/local/lib/python3.10/site-packages (2.0.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/site-packages (2.2.6)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/site-packages (4.67.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/site-packages (2.3.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/site-packages (3.10.3)\n",
      "Requirement already satisfied: urllib3>=1.25.5 in /usr/local/lib/python3.10/site-packages (from requests-cache) (2.5.0)\n",
      "Requirement already satisfied: attrs>=21.2 in /usr/local/lib/python3.10/site-packages (from requests-cache) (25.3.0)\n",
      "Requirement already satisfied: cattrs>=22.2 in /usr/local/lib/python3.10/site-packages (from requests-cache) (25.1.1)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/site-packages (from requests-cache) (4.3.8)\n",
      "Requirement already satisfied: url-normalize>=1.4 in /usr/local/lib/python3.10/site-packages (from requests-cache) (2.2.1)\n",
      "Requirement already satisfied: requests>=2.22 in /usr/local/lib/python3.10/site-packages (from requests-cache) (2.32.4)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/site-packages (from matplotlib) (4.59.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.1.1 in /usr/local/lib/python3.10/site-packages (from cattrs>=22.2->requests-cache) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/site-packages (from cattrs>=22.2->requests-cache) (4.14.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests>=2.22->requests-cache) (2025.7.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests>=2.22->requests-cache) (3.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests>=2.22->requests-cache) (3.4.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests-cache retry-requests numpy tqdm pandas matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c5a086-3ef5-4edb-959b-412a6662d5d6",
   "metadata": {},
   "source": [
    "### Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "15de7645-5027-4fae-9a76-29e64ead6a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"PythonPi\") \\\n",
    "    .master(\"spark://master:7077\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "if len(sys.argv) > 1 and sys.argv[1].isdigit():\n",
    "    partitions = int(sys.argv[1])\n",
    "else:\n",
    "    partitions = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d442a9-449a-4721-a939-512c06e02782",
   "metadata": {},
   "source": [
    "### Extract Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "d2dabeaf-3f28-43d0-9c88-a7da912af4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:====>                                                     (7 + 1) / 99]"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet(\"/opt/spark-data/tlc_trip_record_data/\", header=True, inferSchema=True)\n",
    "selected_df = df.select(\"VendorID\", \"tpep_pickup_datetime\", \"tpep_dropoff_datetime\", \"trip_distance\", \"PULocationID\", \"DOLocationID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2326515c-4007-42b4-855a-51d549c0f8e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+-------------+------------+------------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|trip_distance|PULocationID|DOLocationID|\n",
      "+--------+--------------------+---------------------+-------------+------------+------------+\n",
      "|       1| 2015-10-01 00:04:43|  2015-10-01 00:10:17|          1.6|          25|          49|\n",
      "|       1| 2015-10-01 00:13:58|  2015-10-01 00:51:32|         10.2|          97|         143|\n",
      "|       1| 2015-10-01 00:53:57|  2015-10-01 00:57:18|          1.4|         239|          24|\n",
      "|       1| 2015-10-01 00:59:04|  2015-10-01 01:00:07|          0.4|          24|         166|\n",
      "|       1| 2015-10-01 00:01:45|  2015-10-01 00:09:36|          2.0|          43|         238|\n",
      "|       1| 2015-10-01 00:14:55|  2015-10-01 00:19:55|          0.7|          24|          41|\n",
      "|       1| 2015-10-01 00:43:11|  2015-10-01 00:53:12|          2.8|         162|         238|\n",
      "|       1| 2015-10-01 00:10:30|  2015-10-01 00:12:42|          0.5|         164|         161|\n",
      "|       1| 2015-10-01 00:05:53|  2015-10-01 00:16:47|          2.4|          45|          90|\n",
      "|       1| 2015-10-01 00:39:41|  2015-10-01 00:42:02|          0.6|         230|          68|\n",
      "|       1| 2015-10-01 00:55:11|  2015-10-01 01:20:20|          6.6|         163|         255|\n",
      "|       2| 2015-10-01 00:45:28|  2015-10-01 00:59:21|         2.95|         238|          75|\n",
      "|       1| 2015-10-01 00:03:47|  2015-10-01 00:10:03|          1.1|         164|         107|\n",
      "|       1| 2015-10-01 00:40:07|  2015-10-01 00:46:05|          1.3|         246|         230|\n",
      "|       1| 2015-10-01 00:34:29|  2015-10-01 00:35:06|          0.1|         161|         161|\n",
      "|       1| 2015-10-01 00:37:48|  2015-10-01 00:46:11|          1.4|         163|         233|\n",
      "|       2| 2015-10-01 00:05:28|  2015-10-01 00:10:39|         2.03|         142|         151|\n",
      "|       2| 2015-10-01 00:31:58|  2015-10-01 00:39:36|         1.77|         239|          48|\n",
      "|       1| 2015-10-01 00:20:50|  2015-10-01 00:49:26|         18.6|         132|         166|\n",
      "|       1| 2015-10-01 00:59:39|  2015-10-01 01:14:55|          4.5|         239|          79|\n",
      "+--------+--------------------+---------------------+-------------+------------+------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "selected_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "16a8b91f-0608-4c51-b48d-5cdd098c7f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: long (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp_ntz (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp_ntz (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- PULocationID: long (nullable = true)\n",
      " |-- DOLocationID: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "selected_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9e4ed9f0-a61e-4beb-ba95-fb22c18776dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "776914022"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04ec474-f5e3-4c56-b287-8d6ecbe98bdc",
   "metadata": {},
   "source": [
    "### Transform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "076e83a2-8d72-4442-bcbe-a2924c037ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/30 00:59:26 ERROR TaskSchedulerImpl: Lost executor 20 on 172.18.0.2: Command exited with code 137\n",
      "25/07/30 00:59:26 WARN TaskSetManager: Lost task 20.0 in stage 11.0 (TID 159) (172.18.0.2 executor 20): ExecutorLostFailure (executor 20 exited caused by one of the running tasks) Reason: Command exited with code 137\n",
      "25/07/30 00:59:26 WARN TaskSetManager: Lost task 22.0 in stage 11.0 (TID 161) (172.18.0.2 executor 20): ExecutorLostFailure (executor 20 exited caused by one of the running tasks) Reason: Command exited with code 137\n",
      "25/07/30 00:59:26 WARN TaskSetManager: Lost task 23.0 in stage 11.0 (TID 162) (172.18.0.2 executor 20): ExecutorLostFailure (executor 20 exited caused by one of the running tasks) Reason: Command exited with code 137\n",
      "25/07/30 00:59:26 WARN TaskSetManager: Lost task 26.0 in stage 11.0 (TID 165) (172.18.0.2 executor 20): ExecutorLostFailure (executor 20 exited caused by one of the running tasks) Reason: Command exited with code 137\n",
      "25/07/30 00:59:26 WARN TaskSetManager: Lost task 27.0 in stage 11.0 (TID 166) (172.18.0.2 executor 20): ExecutorLostFailure (executor 20 exited caused by one of the running tasks) Reason: Command exited with code 137\n",
      "25/07/30 00:59:26 WARN TaskSetManager: Lost task 28.0 in stage 11.0 (TID 167) (172.18.0.2 executor 20): ExecutorLostFailure (executor 20 exited caused by one of the running tasks) Reason: Command exited with code 137\n",
      "25/07/30 00:59:26 WARN TaskSetManager: Lost task 29.0 in stage 11.0 (TID 168) (172.18.0.2 executor 20): ExecutorLostFailure (executor 20 exited caused by one of the running tasks) Reason: Command exited with code 137\n",
      "25/07/30 00:59:26 WARN TaskSetManager: Lost task 40.0 in stage 11.0 (TID 179) (172.18.0.2 executor 20): ExecutorLostFailure (executor 20 exited caused by one of the running tasks) Reason: Command exited with code 137\n",
      "25/07/30 00:59:26 WARN TaskSetManager: Lost task 41.0 in stage 11.0 (TID 180) (172.18.0.2 executor 20): ExecutorLostFailure (executor 20 exited caused by one of the running tasks) Reason: Command exited with code 137\n",
      "25/07/30 00:59:26 WARN TaskSetManager: Lost task 42.0 in stage 11.0 (TID 181) (172.18.0.2 executor 20): ExecutorLostFailure (executor 20 exited caused by one of the running tasks) Reason: Command exited with code 137\n",
      "[Stage 6:====>                                                     (7 + 1) / 99]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------------+---------------------------+-------------------+------------------+------------------+\n",
      "|VendorID_nulls|tpep_pickup_datetime_nulls|tpep_dropoff_datetime_nulls|trip_distance_nulls|PULocationID_nulls|DOLocationID_nulls|\n",
      "+--------------+--------------------------+---------------------------+-------------------+------------------+------------------+\n",
      "|             0|                         0|                          0|                  0|                 0|                 0|\n",
      "+--------------+--------------------------+---------------------------+-------------------+------------------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:====>                                                     (7 + 1) / 99]"
     ]
    }
   ],
   "source": [
    "# null 값이 존재하는 row 확인\n",
    "null_counts = selected_df.select([\n",
    "    spark_sum(col(c).isNull().cast(\"int\")).alias(c + \"_nulls\") for c in selected_df.columns\n",
    "])\n",
    "\n",
    "null_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "193ebacb-cd97-4a43-9c5a-55104e58d79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickup < dropoff인 것만 남기기\n",
    "selected_df = selected_df.filter(col(\"tpep_pickup_datetime\") < col(\"tpep_dropoff_datetime\"))\n",
    "\n",
    "# trip_distance > 0인 것만 남기기\n",
    "selected_df = selected_df.filter(col(\"trip_distance\") > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "1efdefb9-5a88-4785-a262-990e24c36484",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_df = selected_df.withColumn(\n",
    "    \"trip_duration_sec\", \n",
    "    (unix_timestamp(\"tpep_dropoff_datetime\") - unix_timestamp(\"tpep_pickup_datetime\"))\n",
    ")\n",
    "selected_df = selected_df.withColumn(\"pickup_hour\", hour(\"tpep_pickup_datetime\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b6eb89-4b2d-4d86-a7fd-8daab4c2e11e",
   "metadata": {},
   "source": [
    "### Data Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e38565-f8b4-4304-adb5-40adfe94ab37",
   "metadata": {},
   "source": [
    "#### Average Distance & Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "9c0d4b5f-9291-4ef0-9add-fc4857921418",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:====>                                                     (7 + 1) / 99]"
     ]
    }
   ],
   "source": [
    "# 평균 거리와 평균 기간 계산\n",
    "averages = selected_df.select(\n",
    "    avg(\"trip_duration_sec\").alias(\"avg_duration_sec\"),\n",
    "    avg(\"trip_distance\").alias(\"avg_trip_distance\")\n",
    ").collect()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "2d3bcbaf-c635-4f54-88c1-3ecc87ac8d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df = pd.DataFrame([{\n",
    "    \"avg_duration_min\": round(averages['avg_duration_sec'] / 60, 2),\n",
    "    \"avg_trip_distance_miles\": round(averages['avg_trip_distance'], 2)\n",
    "}])\n",
    "\n",
    "# CSV로 저장\n",
    "summary_df.to_csv(\"/opt/spark-data/trip_summary.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa18a5b4-99f5-4ac7-9336-e8771ec9d90e",
   "metadata": {},
   "source": [
    "#### Peak Hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e51c6298-5326-47bd-a4a8-98781d42192c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "hourly_counts = selected_df.groupBy(\"pickup_hour\").agg(count(\"*\").alias(\"trip_count\"))\n",
    "\n",
    "# toPandas()로 변환\n",
    "pdf = hourly_counts.orderBy(\"pickup_hour\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f4cd388f-0f00-4c5a-87c6-1d9dcefd7f74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 피크 시간대 찾기\n",
    "peak_hour = pdf.loc[pdf['trip_count'].idxmax(), 'pickup_hour']\n",
    "\n",
    "# 시각화\n",
    "plt.figure(figsize=(12, 6))\n",
    "bars = plt.bar(pdf['pickup_hour'], pdf['trip_count'], color='skyblue')\n",
    "\n",
    "# 피크 시간 강조\n",
    "bars[peak_hour].set_color('red')\n",
    "plt.title(\"Trip Count - Peak Hours\")\n",
    "plt.xlabel(\"Hour (0~23)\")\n",
    "plt.ylabel(\"Trip Count\")\n",
    "plt.xticks(range(0, 24))\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# 피크 시간 레이블 추가\n",
    "plt.text(peak_hour, pdf['trip_count'].max(), f'Peak: {peak_hour}', ha='center', va='bottom', fontsize=12, color='red')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0e7ed3-5943-41ff-9b7b-f8b6efe9d3c2",
   "metadata": {},
   "source": [
    "#### Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "5c7a29a5-8bd7-484c-8ade-3951e21f8386",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:====>                                                     (7 + 1) / 99]"
     ]
    }
   ],
   "source": [
    "# LocationID + 위도/경도 데이터 불러오기\n",
    "zone_df = spark.read.parquet(\"/opt/spark-data/zone_with_coords.parquet\")\n",
    "\n",
    "# join\n",
    "joined_df = selected_df.join(zone_df, selected_df.PULocationID == zone_df.LocationID, how='left').drop('LocationID', 'Borough', 'Zone', 'service_zone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "565278f9-ee81-44a3-a73a-929a2a859fe5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'e' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOpenMeteoRequestsError\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/openmeteo_requests/Client.py:94\u001b[0m, in \u001b[0;36mClient.weather_api\u001b[0;34m(self, url, params, method, verify, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(msg)\n\u001b[0;32m---> 94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/openmeteo_requests/Client.py:74\u001b[0m, in \u001b[0;36mClient._request\u001b[0;34m(self, url, method, params, verify, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m     response_body \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n\u001b[0;32m---> 74\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OpenMeteoRequestsError(response_body)\n\u001b[1;32m     76\u001b[0m response\u001b[38;5;241m.\u001b[39mraise_for_status()\n",
      "\u001b[0;31mOpenMeteoRequestsError\u001b[0m: {'error': True, 'reason': 'Daily API request limit exceeded. Please try again tomorrow.'}",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOpenMeteoRequestsError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[165], line 22\u001b[0m, in \u001b[0;36mfetch_weather_data\u001b[0;34m(lat, lon, start, end)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 22\u001b[0m     responses \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweather_api\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m     response \u001b[38;5;241m=\u001b[39m responses[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/openmeteo_requests/Client.py:103\u001b[0m, in \u001b[0;36mClient.weather_api\u001b[0;34m(self, url, params, method, verify, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfailed to request \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m OpenMeteoRequestsError(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mOpenMeteoRequestsError\u001b[0m: failed to request 'https://archive-api.open-meteo.com/v1/archive': {'error': True, 'reason': 'Daily API request limit exceeded. Please try again tomorrow.'}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[165], line 38\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m날씨 추출 실패 : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     37\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mfetch_weather_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m40.7128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m74.0060\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[0;32mIn[165], line 36\u001b[0m, in \u001b[0;36mfetch_weather_data\u001b[0;34m(lat, lon, start, end)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m spark\u001b[38;5;241m.\u001b[39mcreateDataFrame(df)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m---> 36\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m날씨 추출 실패 : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43me\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'e' is not defined"
     ]
    }
   ],
   "source": [
    "def fetch_weather_data(lat, lon, start=\"2015-01-01\", end=\"2025-07-30\"):\n",
    "    import openmeteo_requests\n",
    "    import requests_cache\n",
    "    from retry_requests import retry\n",
    "    import pandas as pd\n",
    "\n",
    "    cache_session = requests_cache.CachedSession('.cache', expire_after=-1)\n",
    "    retry_session = retry(cache_session, retries=3, backoff_factor=0.2)\n",
    "    client = openmeteo_requests.Client(session=retry_session)\n",
    "\n",
    "    url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "    params = {\n",
    "        \"latitude\": lat,\n",
    "        \"longitude\": lon,\n",
    "        \"start_date\": start,\n",
    "        \"end_date\": end,\n",
    "        \"hourly\": [\"temperature_2m\", \"precipitation\", \"relative_humidity_2m\"],\n",
    "        \"timezone\": \"America/New_York\",\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        responses = client.weather_api(url, params=params)\n",
    "        response = responses[0]\n",
    "        hourly = response.Hourly()\n",
    "        times = hourly.Time()\n",
    "        df = pd.DataFrame({\n",
    "            \"datetime\": pd.to_datetime(times),\n",
    "            \"latitude\": lat,\n",
    "            \"longitude\": lon,\n",
    "            \"temperature_2m\": hourly.Variables(0).ValuesAsNumpy(),\n",
    "            \"precipitation\": hourly.Variables(1).ValuesAsNumpy(),\n",
    "            \"relative_humidity_2m\": hourly.Variables(2).ValuesAsNumpy(),\n",
    "        })\n",
    "        return spark.createDataFrame(df)\n",
    "    except Exception:\n",
    "        print(f\"날씨 추출 실패 : {e}\")\n",
    "        raise\n",
    "print(fetch_weather_data(40.7128, -74.0060))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910eac44-e2c5-4b7a-8a67-046eead8384b",
   "metadata": {},
   "source": [
    "- 보완 필요 (날씨 데이터 수집)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "ed095b52-ce31-4361-a9f5-bec70bea7d9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/30 01:01:05 WARN TaskSetManager: Lost task 0.0 in stage 22.0 (TID 367) (172.18.0.2 executor 21): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 2044, in main\n",
      "    process()\n",
      "  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 2034, in process\n",
      "    out_iter = func(split_index, iterator)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/pyspark/core/rdd.py\", line 5306, in pipeline_func\n",
      "    return func(split, prev_func(split, iterator))\n",
      "  File \"/usr/local/lib/python3.10/site-packages/pyspark/core/rdd.py\", line 5306, in pipeline_func\n",
      "    return func(split, prev_func(split, iterator))\n",
      "  File \"/usr/local/lib/python3.10/site-packages/pyspark/core/rdd.py\", line 705, in func\n",
      "    return f(iterator)\n",
      "  File \"/tmp/ipykernel_177/2454134739.py\", line 3, in fetch_weather_partition\n",
      "ModuleNotFoundError: No module named 'requests_cache'\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:581)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:940)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:925)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:532)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.mutable.Growable.addAll(Growable.scala:61)\n",
      "\tat scala.collection.mutable.Growable.addAll$(Growable.scala:57)\n",
      "\tat scala.collection.mutable.ArrayBuilder.addAll(ArrayBuilder.scala:75)\n",
      "\tat scala.collection.IterableOnceOps.toArray(IterableOnce.scala:1505)\n",
      "\tat scala.collection.IterableOnceOps.toArray$(IterableOnce.scala:1498)\n",
      "\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n",
      "\tat org.apache.spark.api.python.PythonRDD$.$anonfun$runJob$1(PythonRDD.scala:189)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2524)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "\n",
      "25/07/30 01:01:19 WARN TaskSetManager: Lost task 0.1 in stage 22.0 (TID 368) (172.18.0.2 executor 21): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 2044, in main\n",
      "    process()\n",
      "  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 2034, in process\n",
      "    out_iter = func(split_index, iterator)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/pyspark/core/rdd.py\", line 5306, in pipeline_func\n",
      "    return func(split, prev_func(split, iterator))\n",
      "  File \"/usr/local/lib/python3.10/site-packages/pyspark/core/rdd.py\", line 5306, in pipeline_func\n",
      "    return func(split, prev_func(split, iterator))\n",
      "  File \"/usr/local/lib/python3.10/site-packages/pyspark/core/rdd.py\", line 705, in func\n",
      "    return f(iterator)\n",
      "  File \"/tmp/ipykernel_177/2454134739.py\", line 3, in fetch_weather_partition\n",
      "ModuleNotFoundError: No module named 'requests_cache'\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:581)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:940)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:925)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:532)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.mutable.Growable.addAll(Growable.scala:61)\n",
      "\tat scala.collection.mutable.Growable.addAll$(Growable.scala:57)\n",
      "\tat scala.collection.mutable.ArrayBuilder.addAll(ArrayBuilder.scala:75)\n",
      "\tat scala.collection.IterableOnceOps.toArray(IterableOnce.scala:1505)\n",
      "\tat scala.collection.IterableOnceOps.toArray$(IterableOnce.scala:1498)\n",
      "\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n",
      "\tat org.apache.spark.api.python.PythonRDD$.$anonfun$runJob$1(PythonRDD.scala:189)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2524)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "\n",
      "25/07/30 01:01:35 WARN TaskSetManager: Lost task 0.2 in stage 22.0 (TID 369) (172.18.0.2 executor 21): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 2044, in main\n",
      "    process()\n",
      "  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 2034, in process\n",
      "    out_iter = func(split_index, iterator)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/pyspark/core/rdd.py\", line 5306, in pipeline_func\n",
      "    return func(split, prev_func(split, iterator))\n",
      "  File \"/usr/local/lib/python3.10/site-packages/pyspark/core/rdd.py\", line 5306, in pipeline_func\n",
      "    return func(split, prev_func(split, iterator))\n",
      "  File \"/usr/local/lib/python3.10/site-packages/pyspark/core/rdd.py\", line 705, in func\n",
      "    return f(iterator)\n",
      "  File \"/tmp/ipykernel_177/2454134739.py\", line 3, in fetch_weather_partition\n",
      "ModuleNotFoundError: No module named 'requests_cache'\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:581)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:940)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:925)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:532)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.mutable.Growable.addAll(Growable.scala:61)\n",
      "\tat scala.collection.mutable.Growable.addAll$(Growable.scala:57)\n",
      "\tat scala.collection.mutable.ArrayBuilder.addAll(ArrayBuilder.scala:75)\n",
      "\tat scala.collection.IterableOnceOps.toArray(IterableOnce.scala:1505)\n",
      "\tat scala.collection.IterableOnceOps.toArray$(IterableOnce.scala:1498)\n",
      "\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n",
      "\tat org.apache.spark.api.python.PythonRDD$.$anonfun$runJob$1(PythonRDD.scala:189)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2524)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "\n",
      "25/07/30 01:01:49 WARN TaskSetManager: Lost task 0.3 in stage 22.0 (TID 370) (172.18.0.3 executor 19): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 2044, in main\n",
      "    process()\n",
      "  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 2034, in process\n",
      "    out_iter = func(split_index, iterator)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/pyspark/core/rdd.py\", line 5306, in pipeline_func\n",
      "    return func(split, prev_func(split, iterator))\n",
      "  File \"/usr/local/lib/python3.10/site-packages/pyspark/core/rdd.py\", line 5306, in pipeline_func\n",
      "    return func(split, prev_func(split, iterator))\n",
      "  File \"/usr/local/lib/python3.10/site-packages/pyspark/core/rdd.py\", line 705, in func\n",
      "    return f(iterator)\n",
      "  File \"/tmp/ipykernel_177/2454134739.py\", line 3, in fetch_weather_partition\n",
      "ModuleNotFoundError: No module named 'requests_cache'\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:581)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:940)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:925)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:532)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.mutable.Growable.addAll(Growable.scala:61)\n",
      "\tat scala.collection.mutable.Growable.addAll$(Growable.scala:57)\n",
      "\tat scala.collection.mutable.ArrayBuilder.addAll(ArrayBuilder.scala:75)\n",
      "\tat scala.collection.IterableOnceOps.toArray(IterableOnce.scala:1505)\n",
      "\tat scala.collection.IterableOnceOps.toArray$(IterableOnce.scala:1498)\n",
      "\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n",
      "\tat org.apache.spark.api.python.PythonRDD$.$anonfun$runJob$1(PythonRDD.scala:189)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2524)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "\n",
      "25/07/30 01:01:49 ERROR TaskSetManager: Task 0 in stage 22.0 failed 4 times; aborting job\n",
      "[Stage 6:====>                                                     (7 + 1) / 99]"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 22.0 failed 4 times, most recent failure: Lost task 0.3 in stage 22.0 (TID 370) (172.18.0.3 executor 19): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 2044, in main\n    process()\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 2034, in process\n    out_iter = func(split_index, iterator)\n  File \"/usr/local/lib/python3.10/site-packages/pyspark/core/rdd.py\", line 5306, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File \"/usr/local/lib/python3.10/site-packages/pyspark/core/rdd.py\", line 5306, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File \"/usr/local/lib/python3.10/site-packages/pyspark/core/rdd.py\", line 705, in func\n    return f(iterator)\n  File \"/tmp/ipykernel_177/2454134739.py\", line 3, in fetch_weather_partition\nModuleNotFoundError: No module named 'requests_cache'\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:581)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:940)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:925)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:532)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.mutable.Growable.addAll(Growable.scala:61)\n\tat scala.collection.mutable.Growable.addAll$(Growable.scala:57)\n\tat scala.collection.mutable.ArrayBuilder.addAll(ArrayBuilder.scala:75)\n\tat scala.collection.IterableOnceOps.toArray(IterableOnce.scala:1505)\n\tat scala.collection.IterableOnceOps.toArray$(IterableOnce.scala:1498)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.api.python.PythonRDD$.$anonfun$runJob$1(PythonRDD.scala:189)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2524)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)\n\tat scala.collection.immutable.List.foreach(List.scala:334)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)\n\tat scala.Option.foreach(Option.scala:437)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3207)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3141)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3130)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:50)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:1009)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2484)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2505)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2524)\n\tat org.apache.spark.api.python.PythonRDD$.runJob(PythonRDD.scala:189)\n\tat org.apache.spark.api.python.PythonRDD.runJob(PythonRDD.scala)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 2044, in main\n    process()\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 2034, in process\n    out_iter = func(split_index, iterator)\n  File \"/usr/local/lib/python3.10/site-packages/pyspark/core/rdd.py\", line 5306, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File \"/usr/local/lib/python3.10/site-packages/pyspark/core/rdd.py\", line 5306, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File \"/usr/local/lib/python3.10/site-packages/pyspark/core/rdd.py\", line 705, in func\n    return f(iterator)\n  File \"/tmp/ipykernel_177/2454134739.py\", line 3, in fetch_weather_partition\nModuleNotFoundError: No module named 'requests_cache'\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:581)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:940)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:925)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:532)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.mutable.Growable.addAll(Growable.scala:61)\n\tat scala.collection.mutable.Growable.addAll$(Growable.scala:57)\n\tat scala.collection.mutable.ArrayBuilder.addAll(ArrayBuilder.scala:75)\n\tat scala.collection.IterableOnceOps.toArray(IterableOnce.scala:1505)\n\tat scala.collection.IterableOnceOps.toArray$(IterableOnce.scala:1498)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.api.python.PythonRDD$.$anonfun$runJob$1(PythonRDD.scala:189)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2524)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n\t... 1 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[162], line 60\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# mapPartitions 실행 후 DataFrame 생성\u001b[39;00m\n\u001b[1;32m     59\u001b[0m weather_rdd \u001b[38;5;241m=\u001b[39m joined_df\u001b[38;5;241m.\u001b[39mrdd\u001b[38;5;241m.\u001b[39mmapPartitions(fetch_weather_partition)\n\u001b[0;32m---> 60\u001b[0m weather_spark_df \u001b[38;5;241m=\u001b[39m \u001b[43mweather_rdd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoDF\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# 조인할 때 key가 동일해야 하니 컬럼명 통일 필요 (예: joined_df에도 동일한 컬럼명)\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# 조인 시 'pickup_hour', 'tpep_pickup_datetime', 'latitude', 'longitude' 기준으로 조인\u001b[39;00m\n\u001b[1;32m     64\u001b[0m joined_df \u001b[38;5;241m=\u001b[39m joined_df\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m     65\u001b[0m     weather_spark_df,\n\u001b[1;32m     66\u001b[0m     on\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpickup_hour\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtpep_pickup_datetime\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlatitude\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlongitude\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     67\u001b[0m     how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     68\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pyspark/sql/session.py:133\u001b[0m, in \u001b[0;36m_monkey_patch_RDD.<locals>.toDF\u001b[0;34m(self, schema, sampleRatio)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;129m@no_type_check\u001b[39m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtoDF\u001b[39m(\u001b[38;5;28mself\u001b[39m, schema\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sampleRatio\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    100\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;124;03m    Converts current :class:`RDD` into a :class:`DataFrame`\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;124;03m    +---+\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msparkSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreateDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampleRatio\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pyspark/sql/session.py:1599\u001b[0m, in \u001b[0;36mSparkSession.createDataFrame\u001b[0;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[1;32m   1594\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_pyarrow \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, pa\u001b[38;5;241m.\u001b[39mTable):\n\u001b[1;32m   1595\u001b[0m     \u001b[38;5;66;03m# Create a DataFrame from PyArrow Table.\u001b[39;00m\n\u001b[1;32m   1596\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m(SparkSession, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mcreateDataFrame(  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[1;32m   1597\u001b[0m         data, schema, samplingRatio, verifySchema\n\u001b[1;32m   1598\u001b[0m     )\n\u001b[0;32m-> 1599\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_dataframe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1600\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msamplingRatio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverifySchema\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1601\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pyspark/sql/session.py:1641\u001b[0m, in \u001b[0;36mSparkSession._create_dataframe\u001b[0;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[1;32m   1639\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrdd\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RDD\n\u001b[1;32m   1640\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_remote_only() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, RDD):\n\u001b[0;32m-> 1641\u001b[0m     rdd, struct \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_createFromRDD\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprepare\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msamplingRatio\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1642\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1643\u001b[0m     rdd, struct \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_createFromLocal(\n\u001b[1;32m   1644\u001b[0m         \u001b[38;5;28mmap\u001b[39m(prepare, data), schema  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m   1645\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pyspark/sql/session.py:1161\u001b[0m, in \u001b[0;36mSparkSession._createFromRDD\u001b[0;34m(self, rdd, schema, samplingRatio)\u001b[0m\n\u001b[1;32m   1157\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1158\u001b[0m \u001b[38;5;124;03mCreate an RDD for DataFrame from an existing RDD, returns the RDD and schema.\u001b[39;00m\n\u001b[1;32m   1159\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m schema \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(schema, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m-> 1161\u001b[0m     struct \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inferSchema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrdd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msamplingRatio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1162\u001b[0m     converter \u001b[38;5;241m=\u001b[39m _create_converter(struct)\n\u001b[1;32m   1163\u001b[0m     tupled_rdd \u001b[38;5;241m=\u001b[39m rdd\u001b[38;5;241m.\u001b[39mmap(converter)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pyspark/sql/session.py:1098\u001b[0m, in \u001b[0;36mSparkSession._inferSchema\u001b[0;34m(self, rdd, samplingRatio, names)\u001b[0m\n\u001b[1;32m   1077\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_inferSchema\u001b[39m(\n\u001b[1;32m   1078\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1079\u001b[0m     rdd: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRDD[Any]\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1080\u001b[0m     samplingRatio: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1081\u001b[0m     names: Optional[List[\u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1082\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m StructType:\n\u001b[1;32m   1083\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m \u001b[38;5;124;03m    Infer schema from an RDD of Row, dict, or tuple.\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[38;5;124;03m    :class:`pyspark.sql.types.StructType`\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1098\u001b[0m     first \u001b[38;5;241m=\u001b[39m \u001b[43mrdd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfirst\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1099\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(first, Sized) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(first) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1100\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m PySparkValueError(\n\u001b[1;32m   1101\u001b[0m             errorClass\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCANNOT_INFER_EMPTY_SCHEMA\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1102\u001b[0m             messageParameters\u001b[38;5;241m=\u001b[39m{},\n\u001b[1;32m   1103\u001b[0m         )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pyspark/core/rdd.py:2755\u001b[0m, in \u001b[0;36mRDD.first\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2729\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfirst\u001b[39m(\u001b[38;5;28mself\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRDD[T]\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m   2730\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2731\u001b[0m \u001b[38;5;124;03m    Return the first element in this RDD.\u001b[39;00m\n\u001b[1;32m   2732\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2753\u001b[0m \u001b[38;5;124;03m    ValueError: RDD is empty\u001b[39;00m\n\u001b[1;32m   2754\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2755\u001b[0m     rs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2756\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m rs:\n\u001b[1;32m   2757\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m rs[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pyspark/core/rdd.py:2722\u001b[0m, in \u001b[0;36mRDD.take\u001b[0;34m(self, num)\u001b[0m\n\u001b[1;32m   2719\u001b[0m         taken \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2721\u001b[0m p \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(partsScanned, \u001b[38;5;28mmin\u001b[39m(partsScanned \u001b[38;5;241m+\u001b[39m numPartsToTry, totalParts))\n\u001b[0;32m-> 2722\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunJob\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtakeUpToNumLeft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2724\u001b[0m items \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m res\n\u001b[1;32m   2725\u001b[0m partsScanned \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m numPartsToTry\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pyspark/core/context.py:2551\u001b[0m, in \u001b[0;36mSparkContext.runJob\u001b[0;34m(self, rdd, partitionFunc, partitions, allowLocal)\u001b[0m\n\u001b[1;32m   2549\u001b[0m mappedRDD \u001b[38;5;241m=\u001b[39m rdd\u001b[38;5;241m.\u001b[39mmapPartitions(partitionFunc)\n\u001b[1;32m   2550\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2551\u001b[0m sock_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPythonRDD\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunJob\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jsc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmappedRDD\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jrdd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartitions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2552\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(_load_from_socket(sock_info, mappedRDD\u001b[38;5;241m.\u001b[39m_jrdd_deserializer))\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/py4j/java_gateway.py:1362\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1356\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1357\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1358\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1359\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1361\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1362\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1363\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1365\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1366\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pyspark/errors/exceptions/captured.py:282\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpy4j\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotocol\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Py4JJavaError\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 282\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    284\u001b[0m     converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/py4j/protocol.py:327\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    325\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 327\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    329\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    331\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    333\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 22.0 failed 4 times, most recent failure: Lost task 0.3 in stage 22.0 (TID 370) (172.18.0.3 executor 19): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 2044, in main\n    process()\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 2034, in process\n    out_iter = func(split_index, iterator)\n  File \"/usr/local/lib/python3.10/site-packages/pyspark/core/rdd.py\", line 5306, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File \"/usr/local/lib/python3.10/site-packages/pyspark/core/rdd.py\", line 5306, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File \"/usr/local/lib/python3.10/site-packages/pyspark/core/rdd.py\", line 705, in func\n    return f(iterator)\n  File \"/tmp/ipykernel_177/2454134739.py\", line 3, in fetch_weather_partition\nModuleNotFoundError: No module named 'requests_cache'\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:581)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:940)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:925)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:532)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.mutable.Growable.addAll(Growable.scala:61)\n\tat scala.collection.mutable.Growable.addAll$(Growable.scala:57)\n\tat scala.collection.mutable.ArrayBuilder.addAll(ArrayBuilder.scala:75)\n\tat scala.collection.IterableOnceOps.toArray(IterableOnce.scala:1505)\n\tat scala.collection.IterableOnceOps.toArray$(IterableOnce.scala:1498)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.api.python.PythonRDD$.$anonfun$runJob$1(PythonRDD.scala:189)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2524)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)\n\tat scala.collection.immutable.List.foreach(List.scala:334)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)\n\tat scala.Option.foreach(Option.scala:437)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3207)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3141)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3130)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:50)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:1009)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2484)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2505)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2524)\n\tat org.apache.spark.api.python.PythonRDD$.runJob(PythonRDD.scala:189)\n\tat org.apache.spark.api.python.PythonRDD.runJob(PythonRDD.scala)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 2044, in main\n    process()\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 2034, in process\n    out_iter = func(split_index, iterator)\n  File \"/usr/local/lib/python3.10/site-packages/pyspark/core/rdd.py\", line 5306, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File \"/usr/local/lib/python3.10/site-packages/pyspark/core/rdd.py\", line 5306, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File \"/usr/local/lib/python3.10/site-packages/pyspark/core/rdd.py\", line 705, in func\n    return f(iterator)\n  File \"/tmp/ipykernel_177/2454134739.py\", line 3, in fetch_weather_partition\nModuleNotFoundError: No module named 'requests_cache'\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:581)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:940)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:925)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:532)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.mutable.Growable.addAll(Growable.scala:61)\n\tat scala.collection.mutable.Growable.addAll$(Growable.scala:57)\n\tat scala.collection.mutable.ArrayBuilder.addAll(ArrayBuilder.scala:75)\n\tat scala.collection.IterableOnceOps.toArray(IterableOnce.scala:1505)\n\tat scala.collection.IterableOnceOps.toArray$(IterableOnce.scala:1498)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.api.python.PythonRDD$.$anonfun$runJob$1(PythonRDD.scala:189)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2524)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n\t... 1 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:====>                                                     (7 + 1) / 99]"
     ]
    }
   ],
   "source": [
    "def fetch_weather_partition(rows):\n",
    "    import openmeteo_requests\n",
    "    import requests_cache\n",
    "    from retry_requests import retry\n",
    "\n",
    "    cache_session = requests_cache.CachedSession('.cache', expire_after=-1)\n",
    "    retry_session = retry(cache_session, retries=3, backoff_factor=0.2)\n",
    "    openmeteo = openmeteo_requests.Client(session=retry_session)\n",
    "\n",
    "    results = []\n",
    "    for row in rows:\n",
    "        hour = row.pickup_hour\n",
    "        date = row.tpep_pickup_datetime\n",
    "        lat = row.latitude\n",
    "        lon = row.longitude\n",
    "\n",
    "        url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "        params = {\n",
    "            \"latitude\": lat,\n",
    "            \"longitude\": lon,\n",
    "            \"start_date\": date.strftime(\"%Y-%m-%d\"),\n",
    "            \"end_date\": date.strftime(\"%Y-%m-%d\"),\n",
    "            \"hourly\": [\"temperature_2m\", \"precipitation\", \"relative_humidity_2m\"],\n",
    "            \"timezone\": \"America/New_York\",\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            responses = openmeteo.weather_api(url, params=params)\n",
    "            response = responses[0]\n",
    "\n",
    "            hourly = response.Hourly()\n",
    "            temp_arr = hourly.Variables(0).ValuesAsNumpy()\n",
    "            prec_arr = hourly.Variables(1).ValuesAsNumpy()\n",
    "            hum_arr = hourly.Variables(2).ValuesAsNumpy()\n",
    "\n",
    "            results.append({\n",
    "                \"pickup_hour\": hour,\n",
    "                \"tpep_pickup_datetime\": date,\n",
    "                \"latitude\": lat,\n",
    "                \"longitude\": lon,\n",
    "                \"temperature_2m\": float(temp_arr[hour]),\n",
    "                \"precipitation\": float(prec_arr[hour]),\n",
    "                \"relative_humidity_2m\": float(hum_arr[hour]),\n",
    "            })\n",
    "        except Exception as e:\n",
    "            results.append({\n",
    "                \"pickup_hour\": hour,\n",
    "                \"tpep_pickup_datetime\": date,\n",
    "                \"latitude\": lat,\n",
    "                \"longitude\": lon,\n",
    "                \"temperature_2m\": None,\n",
    "                \"precipitation\": None,\n",
    "                \"relative_humidity_2m\": None,\n",
    "            })\n",
    "    return iter(results)\n",
    "\n",
    "\n",
    "# mapPartitions 실행 후 DataFrame 생성\n",
    "weather_rdd = joined_df.rdd.mapPartitions(fetch_weather_partition)\n",
    "weather_spark_df = weather_rdd.toDF()\n",
    "\n",
    "# 조인할 때 key가 동일해야 하니 컬럼명 통일 필요 (예: joined_df에도 동일한 컬럼명)\n",
    "# 조인 시 'pickup_hour', 'tpep_pickup_datetime', 'latitude', 'longitude' 기준으로 조인\n",
    "joined_df = joined_df.join(\n",
    "    weather_spark_df,\n",
    "    on=[\"pickup_hour\", \"tpep_pickup_datetime\", \"latitude\", \"longitude\"],\n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a892e0-c583-40fe-a02b-f82b798efde9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "0cac3a46-6f78-4f99-be9c-f06b0f367a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
